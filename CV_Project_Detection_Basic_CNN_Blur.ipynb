{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qx54Kv1PQZuF",
    "outputId": "888f156c-a175-4076-bcc9-271427c5011d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ap6624/CV\n",
      "Au  Tp\tau_list.txt  tp_list.txt\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd  /content/drive/'My Drive'/'CV Project'/\n",
    "!pwd\n",
    "!ls /scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LzFfut1EUe1E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageFilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ela(dir, filename):\n",
    "    path = os.path.join(dir, filename)\n",
    "    temp_img = 'tmp_img_bw.jpg'\n",
    "\n",
    "    image = Image.open(path)\n",
    "    filtered_image = image.convert('RGB').filter(ImageFilter.BoxBlur(0.5))\n",
    "    filtered_image.save(temp_img, 'JPEG', quality = 90)\n",
    "    \n",
    "    temp_image = Image.open(temp_img)\n",
    "    \n",
    "    ela_image = ImageChops.difference(filtered_image, temp_image)\n",
    "    \n",
    "    extremas = ela_image.getextrema()\n",
    "    max_ext = max([x[1] for x in extremas])\n",
    "    if max_ext == 0:\n",
    "        scale = 255.0\n",
    "    else:\n",
    "        scale = 255.0 / max_ext\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image)\n",
    "    ela_image = ela_image.enhance(scale)\n",
    "\n",
    "    result = np.array(ela_image.resize((128,128))).flatten()/255\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyXZQ667UTzQ",
    "outputId": "14f1cf44-3feb-4536-8b9c-007949d623eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7492/7492 [02:01<00:00, 61.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentic Images:\n",
      "Train Size: 7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5123/5123 [01:10<00:00, 72.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tampered Images:\n",
      "Train+Fake Size: 9501\n",
      "Shape of Train Data\n",
      "(9501, 49152)\n"
     ]
    }
   ],
   "source": [
    "authentic_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Au'\n",
    "tampered_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Tp'\n",
    "\n",
    "X_arr = []\n",
    "y_arr = []\n",
    "\n",
    "for dir, _, files in os.walk(authentic_path):\n",
    "    for filename in tqdm(files):\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            X_arr.append(get_ela(dir, filename))\n",
    "            y_arr.append(0)\n",
    "\n",
    "num_authentic = len(X_arr)\n",
    "print(\"Authentic Images:\", num_authentic)\n",
    "\n",
    "for dir, _, files in os.walk(tampered_path):\n",
    "    for filename in tqdm(files):\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            X_arr.append(get_ela(dir, filename))\n",
    "            y_arr.append(1)\n",
    "            \n",
    "print(\"Tampered Images:\", len(X_arr) - num_authentic)\n",
    "\n",
    "X = np.array(X_arr)\n",
    "# X = X_arr\n",
    "y = y_arr\n",
    "\n",
    "print(\"Shape of Train Data\")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9501, 49152)\n",
      "(9501, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "y = to_categorical(y, 2)\n",
    "X = X.reshape(-1, 128, 128, 3)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ytupTNP2W8Qk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 128, 128, 3) (7600, 2)\n",
      "(1901, 128, 128, 3) (1901, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_save_path = 'ELA_extracted_X.npy'\n",
    "# y_save_path = 'ELA_extracted_y.npy'\n",
    "# with open(X_save_path, 'wb') as f1:\n",
    "#     np.save(f1, X)\n",
    "# with open(y_save_path, 'wb') as f2:\n",
    "#     np.save(f2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZysfJUlpXY2N"
   },
   "source": [
    "##Using a Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDf6GjIPXYVW",
    "outputId": "ab9fe6b2-a466-4ed3-de24-87c19d76f6e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 19:18:25.415095: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-15 19:18:25.416462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-15 19:18:26.013289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-15 19:18:26.013363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-15 19:18:26.341275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-15 19:18:26.341385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-15 19:18:26.544787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-15 19:18:26.980458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-15 19:18:26.980654: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: /ext3/miniconda3/lib/python3.9/site-packages/tensorflow/python/../../../../libcusolver.so.10: invalid ELF header; LD_LIBRARY_PATH: .::/.singularity.d/libs\n",
      "2021-12-15 19:18:27.028641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-15 19:18:27.402210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-15 19:18:27.402245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-15 19:18:27.404052: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 19:18:27.404167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-15 19:18:27.404177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-12-15 19:18:27.404186: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,234,114\n",
      "Trainable params: 1,234,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "basicCNNModel = Sequential()\n",
    "basicCNNModel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',activation = 'relu',input_shape = (128,128,3)))\n",
    "basicCNNModel.add(MaxPool2D(pool_size = (2,2)))\n",
    "basicCNNModel.add(Dropout(0.1))\n",
    "\n",
    "basicCNNModel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',activation = 'relu'))\n",
    "basicCNNModel.add(MaxPool2D(pool_size = (2,2)))\n",
    "basicCNNModel.add(Dropout(0.1))\n",
    "\n",
    "basicCNNModel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid',activation = 'relu'))\n",
    "basicCNNModel.add(MaxPool2D(pool_size = (2,2)))\n",
    "basicCNNModel.add(Dropout(0.2))\n",
    "\n",
    "basicCNNModel.add(Flatten())\n",
    "basicCNNModel.add(Dense(256, activation = 'relu'))\n",
    "basicCNNModel.add(Dropout(0.3))\n",
    "basicCNNModel.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "\n",
    "basicCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7MAfP28BX8tr"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'BasicCNN_Detection_Blur/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 32\n",
    "opt = Adam(learning_rate = 0.001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',patience = 2, mode = 'auto', min_delta = 0)\n",
    "\n",
    "basicCNNModel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PuKFw-5HZunf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 19:20:48.596334: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-15 19:20:48.609519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "238/238 [==============================] - 544s 2s/step - loss: 0.4847 - accuracy: 0.7775 - val_loss: 0.4113 - val_accuracy: 0.7354\n",
      "Epoch 2/8\n",
      "238/238 [==============================] - 538s 2s/step - loss: 0.4372 - accuracy: 0.7837 - val_loss: 0.4069 - val_accuracy: 0.7181\n",
      "Epoch 3/8\n",
      "238/238 [==============================] - 540s 2s/step - loss: 0.4187 - accuracy: 0.7797 - val_loss: 0.3918 - val_accuracy: 0.7253\n",
      "Epoch 4/8\n",
      "238/238 [==============================] - 544s 2s/step - loss: 0.4949 - accuracy: 0.7775 - val_loss: 0.4212 - val_accuracy: 0.7406\n",
      "Epoch 5/8\n",
      "238/238 [==============================] - 538s 2s/step - loss: 0.4671 - accuracy: 0.7731 - val_loss: 0.4013 - val_accuracy: 0.7751\n",
      "Epoch 6/8\n",
      "238/238 [==============================] - 540s 2s/step - loss: 0.4284 - accuracy: 0.7869 - val_loss: 0.3847 - val_accuracy: 0.7954\n",
      "Epoch 7/8\n",
      "238/238 [==============================] - 544s 2s/step - loss: 0.4143 - accuracy: 0.8071 - val_loss: 0.3919 - val_accuracy: 0.7852\n",
      "Epoch 8/8\n",
      "238/238 [==============================] - 538s 2s/step - loss: 0.4310 - accuracy: 0.7855 - val_loss: 0.4067 - val_accuracy: 0.7798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x146ea9de24c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 8\n",
    "batch_size = 32\n",
    "\n",
    "basicCNNModel.fit(X_train,y_train,batch_size = batch_size,epochs = epochs,validation_data = (X_test, y_test),callbacks = [early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "35mRnoEgrYBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1493\n",
      "           1       1.00      0.06      0.11       408\n",
      "\n",
      "    accuracy                           0.80      1901\n",
      "   macro avg       0.90      0.53      0.50      1901\n",
      "weighted avg       0.84      0.80      0.72      1901\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = basicCNNModel.predict(X_test)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "\n",
    "cfm = confusion_matrix(Y_true, Y_pred_classes) \n",
    "plot_confusion_matrix(cfm, classes = range(2))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CV Project - Detection CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
