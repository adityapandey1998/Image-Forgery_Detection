{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx54Kv1PQZuF",
        "outputId": "ebab4543-05e0-4046-a2c0-5ea8ba1116c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/CV Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd  /content/drive/'My Drive'/'CV Project'/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LzFfut1EUe1E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xavx7igSUnnz"
      },
      "outputs": [],
      "source": [
        "def get_ela(dir, filename):\n",
        "    path = os.path.join(dir, filename)\n",
        "    temp_img = 'tmp_img_bw.jpg'\n",
        "\n",
        "    image = Image.open(path)\n",
        "    filtered_image = image.convert('RGB').filter(ImageFilter.BoxBlur(0.5))\n",
        "    filtered_image.save(temp_img, 'JPEG', quality = 90)\n",
        "    \n",
        "    temp_image = Image.open(temp_img)\n",
        "    \n",
        "    ela_image = ImageChops.difference(filtered_image, temp_image)\n",
        "    \n",
        "    extremas = ela_image.getextrema()\n",
        "    max_ext = max([x[1] for x in extremas])\n",
        "    if max_ext == 0:\n",
        "        scale = 255.0\n",
        "    else:\n",
        "        scale = 255.0 / max_ext\n",
        "    \n",
        "    ela_image = ImageEnhance.Brightness(ela_image)\n",
        "    ela_image = ela_image.enhance(scale)\n",
        "\n",
        "    result = np.array(ela_image.resize((128,128))).flatten()/255\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyXZQ667UTzQ",
        "outputId": "7d880b58-dbd9-4bac-a22f-1c539535a2f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 6904/7492 [02:29<00:10, 55.93it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41487\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "100%|██████████| 7492/7492 [02:42<00:00, 46.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authentic Images: 7437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5123/5123 [01:10<00:00, 72.61it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tampered Images: 2064\n",
            "Shape of Train Data\n",
            "(9501, 49152)\n"
          ]
        }
      ],
      "source": [
        "authentic_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Au'\n",
        "tampered_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Tp'\n",
        "\n",
        "X_arr = []\n",
        "y_arr = []\n",
        "\n",
        "for dir, _, files in os.walk(authentic_path):\n",
        "    for filename in tqdm(files):\n",
        "        if filename.endswith('jpg') or filename.endswith('png'):\n",
        "            X_arr.append(get_ela(dir, filename))\n",
        "            y_arr.append(0)\n",
        "\n",
        "num_authentic = len(X_arr)\n",
        "print(\"Authentic Images:\", num_authentic)\n",
        "\n",
        "for dir, _, files in os.walk(tampered_path):\n",
        "    for filename in tqdm(files):\n",
        "        if filename.endswith('jpg') or filename.endswith('png'):\n",
        "            X_arr.append(get_ela(dir, filename))\n",
        "            y_arr.append(1)\n",
        "            \n",
        "print(\"Tampered Images:\", len(X_arr) - num_authentic)\n",
        "\n",
        "X = np.array(X_arr)\n",
        "# X = X_arr\n",
        "y = y_arr\n",
        "\n",
        "print(\"Shape of Train Data\")\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_1IyO3fVp_-",
        "outputId": "cf12a19c-0c3f-469f-93c2-181b955683c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9501, 49152)\n",
            "(9501, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X_arr)\n",
        "y = y_arr\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "y = to_categorical(y, 2)\n",
        "X = X.reshape(-1, 128, 128, 3)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OZVUNHFIbt9S"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytupTNP2W8Qk",
        "outputId": "75bc5bd0-7fbf-4417-b841-bd8a0114858f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7600, 128, 128, 3) (7600, 2)\n",
            "(1901, 128, 128, 3) (1901, 2)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_save_path = 'ELA_extracted_X.npy'\n",
        "# y_save_path = 'ELA_extracted_y.npy'\n",
        "# with open(X_save_path, 'wb') as f1:\n",
        "#     np.save(f1, X)\n",
        "# with open(y_save_path, 'wb') as f2:\n",
        "#     np.save(f2, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZysfJUlpXY2N"
      },
      "source": [
        "##Using a Basic CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDf6GjIPXYVW",
        "outputId": "1e080927-838d-4c7b-fbd4-8bfc3ebc26e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16777472  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,168,194\n",
            "Trainable params: 17,167,298\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "basicCNNModel = Sequential()\n",
        "basicCNNModel.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(128,128,3), padding=\"same\", activation='relu'))\n",
        "basicCNNModel.add(Dropout(0.25))\n",
        "basicCNNModel.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\", activation='relu'))\n",
        "basicCNNModel.add(BatchNormalization(momentum=0.8))\n",
        "basicCNNModel.add(Dropout(0.25))\n",
        "basicCNNModel.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\", activation='relu'))\n",
        "basicCNNModel.add(BatchNormalization(momentum=0.8))\n",
        "basicCNNModel.add(Dropout(0.25))\n",
        "basicCNNModel.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\", activation='relu'))\n",
        "basicCNNModel.add(BatchNormalization(momentum=0.8))\n",
        "basicCNNModel.add(Dropout(0.25))\n",
        "basicCNNModel.add(Flatten())\n",
        "basicCNNModel.add(Dense(256, activation = \"relu\"))\n",
        "basicCNNModel.add(Dropout(0.5))\n",
        "basicCNNModel.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "\n",
        "basicCNNModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MAfP28BX8tr",
        "outputId": "d3e9662a-bf3f-49fc-c0c4-b9dcd57712c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "checkpoint_filepath = 'BasicCNNwithBatchNorm_Detection/checkpoint'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "opt = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy',patience = 2,mode = 'auto', min_delta = 0)\n",
        "\n",
        "basicCNNModel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuKFw-5HZunf",
        "outputId": "17e46d0d-37a4-4565-ddac-1d8d60c3c33c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "237/237 [==============================] - 34s 105ms/step - loss: 0.5785 - accuracy: 0.8011 - val_loss: 0.5780 - val_accuracy: 0.5197\n",
            "Epoch 2/10\n",
            "237/237 [==============================] - 25s 106ms/step - loss: 0.3986 - accuracy: 0.8267 - val_loss: 0.4593 - val_accuracy: 0.7864\n",
            "Epoch 3/10\n",
            "237/237 [==============================] - 24s 103ms/step - loss: 0.3607 - accuracy: 0.8272 - val_loss: 0.6392 - val_accuracy: 0.6549\n",
            "Epoch 4/10\n",
            "237/237 [==============================] - 24s 101ms/step - loss: 0.3360 - accuracy: 0.8324 - val_loss: 0.5776 - val_accuracy: 0.6191\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec3b70ac10>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "aug = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, fill_mode=\"nearest\")\n",
        "\n",
        "# basicCNNModel.fit(X_train,y_train,batch_size = batch_size,epochs = epochs,validation_data = (X_test, y_test),callbacks = [early_stopping, model_checkpoint_callback])\n",
        "\n",
        "basicCNNModel.fit_generator(aug.flow(X_train, y_train, batch_size =  batch_size), steps_per_epoch=(len(X_train) /batch_size),epochs = epochs,validation_data = (X_test, y_test),callbacks = [early_stopping, model_checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "35mRnoEgrYBU",
        "outputId": "6b6200d0-9f1f-429c-9500-7f54841fc57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.59      0.71      1496\n",
            "           1       0.32      0.73      0.45       405\n",
            "\n",
            "    accuracy                           0.62      1901\n",
            "   macro avg       0.61      0.66      0.58      1901\n",
            "weighted avg       0.77      0.62      0.65      1901\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "y_pred = basicCNNModel.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred,axis = 1) \n",
        "y_true = np.argmax(y_test,axis = 1) \n",
        "\n",
        "cfm = confusion_matrix(y_true, y_pred_classes) \n",
        "plot_confusion_matrix(cfm, classes = range(2))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CV_Project_Detection_Basic_CNN_BN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
