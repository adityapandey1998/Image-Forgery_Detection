{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qx54Kv1PQZuF",
    "outputId": "888f156c-a175-4076-bcc9-271427c5011d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ap6624/CV\n",
      "Au  Tp\tau_list.txt  tp_list.txt\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd  /content/drive/'My Drive'/'CV Project'/\n",
    "!pwd\n",
    "!ls /scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LzFfut1EUe1E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:10:22.783638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xavx7igSUnnz"
   },
   "outputs": [],
   "source": [
    "def get_ela(dir, filename):\n",
    "    path = os.path.join(dir, filename)\n",
    "    temp_img = 'tmp_img_bw.jpg'\n",
    "\n",
    "    image = Image.open(path)\n",
    "    filtered_image = image.convert('RGB').filter(ImageFilter.BoxBlur(0.5))\n",
    "    filtered_image.save(temp_img, 'JPEG', quality = 90)\n",
    "    \n",
    "    temp_image = Image.open(temp_img)\n",
    "    \n",
    "    ela_image = ImageChops.difference(filtered_image, temp_image)\n",
    "    \n",
    "    extremas = ela_image.getextrema()\n",
    "    max_ext = max([x[1] for x in extremas])\n",
    "    if max_ext == 0:\n",
    "        scale = 255.0\n",
    "    else:\n",
    "        scale = 255.0 / max_ext\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image)\n",
    "    ela_image = ela_image.enhance(scale)\n",
    "\n",
    "    result = np.array(ela_image.resize((128,128))).flatten()/255\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyXZQ667UTzQ",
    "outputId": "14f1cf44-3feb-4536-8b9c-007949d623eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7492/7492 [01:42<00:00, 73.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentic Images:\n",
      "Train Size: 7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5123/5123 [00:38<00:00, 133.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tampered Images:\n",
      "Train+Fake Size: 9501\n",
      "Shape of Train Data\n",
      "(9501, 49152)\n"
     ]
    }
   ],
   "source": [
    "authentic_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Au'\n",
    "tampered_path = '/scratch/ap6624/CV/casia2groundtruth/CASIA2.0_revised/Tp'\n",
    "\n",
    "X_arr = []\n",
    "y_arr = []\n",
    "\n",
    "for dir, _, files in os.walk(authentic_path):\n",
    "    for filename in tqdm(files):\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            X_arr.append(get_ela(dir, filename))\n",
    "            y_arr.append(0)\n",
    "\n",
    "num_authentic = len(X_arr)\n",
    "print(\"Authentic Images:\", num_authentic)\n",
    "\n",
    "for dir, _, files in os.walk(tampered_path):\n",
    "    for filename in tqdm(files):\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            X_arr.append(get_ela(dir, filename))\n",
    "            y_arr.append(1)\n",
    "            \n",
    "print(\"Tampered Images:\", len(X_arr) - num_authentic)\n",
    "\n",
    "X = np.array(X_arr)\n",
    "# X = X_arr\n",
    "y = y_arr\n",
    "\n",
    "print(\"Shape of Train Data\")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9501, 49152)\n",
      "(9501, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "y = to_categorical(y, 2)\n",
    "X = X.reshape(-1, 128, 128, 3)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ytupTNP2W8Qk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 128, 128, 3) (7600, 2)\n",
      "(1901, 128, 128, 3) (1901, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZysfJUlpXY2N"
   },
   "source": [
    "##Using a Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDf6GjIPXYVW",
    "outputId": "ab9fe6b2-a466-4ed3-de24-87c19d76f6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 24,155,554\n",
      "Trainable params: 567,842\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "\n",
    "resNetCNN = Sequential()\n",
    "resnet50 = ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet')\n",
    "resNetCNN.add(resnet50)\n",
    "resNetCNN.add(Dense(256, activation = 'relu'))\n",
    "resNetCNN.add(Dropout(0.1))\n",
    "resNetCNN.add(Dense(128, activation='relu'))\n",
    "resNetCNN.add(Dense(64, activation='relu'))\n",
    "resNetCNN.add(Dropout(0.2))\n",
    "resNetCNN.add(Dense(32, activation='relu'))\n",
    "resNetCNN.add(Dropout(0.3))\n",
    "resNetCNN.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "resNetCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7MAfP28BX8tr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:15:43.231591: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-15 18:15:43.231625: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-15 18:15:43.231764: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-15 18:15:43.231815: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = 'ResNetCNN_Detection/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "opt = Adam(learning_rate = 0.001, decay = 0.001/epochs)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',min_delta = 0,patience = 2,mode = 'auto')\n",
    "\n",
    "resNetCNN.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PuKFw-5HZunf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 18:15:48.770645: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-15 18:15:48.782490: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/238 [..............................] - ETA: 14:43 - loss: 0.7133 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/238 [..............................] - ETA: 4:47 - loss: 0.6903 - accuracy: 0.6797 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 128s 1s/step - loss: 0.5583 - accuracy: 0.8774 - val_loss: 2.5174 - val_accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 179s 2s/step - loss: 0.4352 - accuracy: 0.8839 - val_loss: 2.5161 - val_accuracy: 0.7992\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 179s 2s/step - loss: 0.3354 - accuracy: 0.8815 - val_loss: 1.9106 - val_accuracy: 0.8018\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 178s 2s/step - loss: 0.2802 - accuracy: 0.8840 - val_loss: 1.7302 - val_accuracy: 0.7964\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 178s 2s/step - loss: 0.2416 - accuracy: 0.9042 - val_loss: 1.5106 - val_accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 179s 2s/step - loss: 0.1722 - accuracy: 0.9112 - val_loss: 1.1106 - val_accuracy: 0.8124\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 178s 2s/step - loss: 0.1023 - accuracy: 0.9224 - val_loss: 0.8289 - val_accuracy: 0.8272\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 179s 2s/step - loss: 0.0917 - accuracy: 0.9205 - val_loss: 0.5562 - val_accuracy: 0.8242\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 178s 2s/step - loss: 0.0832 - accuracy: 0.9192 - val_loss: 0.3376 - val_accuracy: 0.8464\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 180s 2s/step - loss: 0.0501 - accuracy: 0.9216 - val_loss: 0.3041 - val_accuracy: 0.8302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e6284330d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "resNetCNN.fit(X_train,y_train,batch_size = batch_size,epochs = epochs,validation_data = (X_test, y_test),callbacks = [early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "35mRnoEgrYBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      1481\n",
      "           1       0.66      0.91      0.76       420\n",
      "\n",
      "    accuracy                           0.88      1901\n",
      "   macro avg       0.81      0.89      0.84      1901\n",
      "weighted avg       0.90      0.88      0.88      1901\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = basicCNNModel.predict(X_test)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "\n",
    "cfm = confusion_matrix(Y_true, Y_pred_classes) \n",
    "plot_confusion_matrix(cfm, classes = [0,1])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CV Project - Detection CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
